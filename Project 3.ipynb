{"cells":[{"cell_type":"markdown","id":"e5c787ff","metadata":{"id":"e5c787ff"},"source":["# Project 3\n","\n","Authors: Ari and Lucas\n","\n","In the following exercise, we're going to analyze the Names corpus and build a gender classifier. First step is to load the Names corpus and split the data into the three sections we need: 500 words for the test set, 500 words for the dev-test set, 6944 words for the training set."]},{"cell_type":"code","execution_count":45,"id":"1ad6f9cc","metadata":{"id":"1ad6f9cc","executionInfo":{"status":"ok","timestamp":1751873945063,"user_tz":240,"elapsed":8,"user":{"displayName":"Ariann C","userId":"03460121609660078047"}}},"outputs":[],"source":["import nltk\n","#nltk.download('names')\n","from nltk.corpus import names\n","import random\n","from collections import defaultdict\n","import soundex\n","\n","soundex_instance = soundex.Soundex()\n","#Load and shuffle the names\n","labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n","                 [(name, 'female') for name in names.words('female.txt')])\n","random.shuffle(labeled_names)\n","\n","#Split the data\n","test_names = labeled_names[:500]\n","dev_test_names = labeled_names[500:1000]\n","train_names = labeled_names[1000:]"]},{"cell_type":"markdown","source":["For our classifiers, we used Naive Bayes and Decision Trees to compare their performances as well as trying to improve past a basic version of these. Below are the initial classifiers with only one extracting feature: name length."],"metadata":{"id":"1OXcjt-8foSl"},"id":"1OXcjt-8foSl"},{"cell_type":"code","source":["def gender_features_basic(name):\n","    features = {\n","        'length': len(name)\n","        }\n","    return features\n","\n","#Prepare the feature sets with the one feature extractor\n","train_set_basic = [(gender_features_basic(name), gender) for (name, gender) in train_names]\n","dev_test_set_basic = [(gender_features_basic(name), gender) for (name, gender) in dev_test_names]\n","test_set_basic = [(gender_features_basic(name), gender) for (name, gender) in test_names]\n","\n","#Train and evaluate the Naive Bayes classifier\n","classifier_nb = nltk.NaiveBayesClassifier.train(train_set_basic)\n","accuracy_nb = nltk.classify.accuracy(classifier_nb, dev_test_set_basic)\n","print(f\"Naive Bayes accuracy with a basic extractor on dev-test set: {accuracy_nb:.4f}\")\n","\n","#Train and evaluate the Decision Tree classifier\n","classifier_dt = nltk.DecisionTreeClassifier.train(train_set_basic)\n","accuracy_dt = nltk.classify.accuracy(classifier_dt, dev_test_set_basic)\n","print(f\"Decision Tree accuracy with a basic extractor on dev-test set: {accuracy_dt:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SJtKmoifnbd","executionInfo":{"status":"ok","timestamp":1751869887930,"user_tz":240,"elapsed":194,"user":{"displayName":"Ariann C","userId":"03460121609660078047"}},"outputId":"55584981-330a-4cbc-b431-073fe9d52672"},"id":"0SJtKmoifnbd","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes accuracy with a basic extractor on dev-test set: 0.6280\n","Decision Tree accuracy with a basic extractor on dev-test set: 0.6280\n"]}]},{"cell_type":"markdown","source":["We can see that the using name length as our only feature does make the classifier do better than the average (since it's just predicting from two values, male and female, the classifier should be right 50% of the time so the average accuracy is 50% by randomly guessing alone). Both classifiers provided the same accuracies meaning that their differences in methods as not stray away from each other in this simple one feature version. Accuracies in the 60s is not enough to be used so it's time to add some improvements to increase it.\n","\n","To make improvements, we need to add more extracting features to our function (gender_features_soundex_package). Some new features we added are:\n","\n","*   length: Name length (used previously)\n","*   first_letter: First letter\n","*   last_letter: Last letter\n","*   Prefix2: First 2 letters\n","*   Prefix3: First 3 letters\n","*   Suffix2: Last 2 letters\n","*   Suffix3: Last 3 letters\n","*   vowel_count: Vowel count\n","*   consonant_count: Consonant count\n","*   soundex: phonetic code to group similar names\n","\n","The last two are for loops to create features for every 2 letter combination (bigram) and 3 letter combination (trigram) in the names.\n","\n","\n","\n"],"metadata":{"id":"eFUNTdZclda5"},"id":"eFUNTdZclda5"},{"cell_type":"code","execution_count":43,"id":"81442d3e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81442d3e","executionInfo":{"status":"ok","timestamp":1751873392975,"user_tz":240,"elapsed":43865,"user":{"displayName":"Ariann C","userId":"03460121609660078047"}},"outputId":"0de4c47c-7e72-48e8-fd32-37e7261e3564"},"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes accuracy with soundex package on dev-test set: 0.8560\n","Decision Tree accuracy with soundex package on dev-test set: 0.7060\n"]}],"source":["def gender_features_soundex_package(name):\n","    name_lower = name.lower()\n","    features = {\n","        'length': len(name),\n","        'first_letter': name_lower[0],\n","        'last_letter': name_lower[-1],\n","        'prefix2': name_lower[:1],\n","        'prefix3': name_lower[:2],\n","        'suffix2': name_lower[-2:],\n","        'suffix3': name_lower[-3:],\n","        'vowel_count': sum(1 for char in name_lower if char in 'aeiou'),\n","        'consonant_count': sum(1 for char in name_lower if char not in 'aeiou'),\n","        'soundex': soundex_instance.soundex(name)\n","    }\n","    #Add character n-grams\n","    for i in range(len(name_lower) - 1):\n","        features[f'bigram_{name_lower[i:i+2]}'] = True\n","    for i in range(len(name_lower) - 2):\n","        features[f'trigram_{name_lower[i:i+3]}'] = True\n","\n","    return features\n","\n","#Prepare the feature sets with the new feature extractor\n","train_set_pkg = [(gender_features_soundex_package(name), gender) for (name, gender) in train_names]\n","dev_test_set_pkg = [(gender_features_soundex_package(name), gender) for (name, gender) in dev_test_names]\n","test_set_pkg = [(gender_features_soundex_package(name), gender) for (name, gender) in test_names]\n","\n","#Train and evaluate the Naive Bayes classifier\n","classifier_nb_pkg = nltk.NaiveBayesClassifier.train(train_set_pkg)\n","accuracy_nb_pkg = nltk.classify.accuracy(classifier_nb_pkg, dev_test_set_pkg)\n","print(f\"Naive Bayes accuracy with soundex package on dev-test set: {accuracy_nb_pkg:.4f}\")\n","\n","#Train and evaluate the Decision Tree classifier\n","classifier_dt_pkg = nltk.DecisionTreeClassifier.train(train_set_pkg)\n","accuracy_dt_pkg = nltk.classify.accuracy(classifier_dt_pkg, dev_test_set_pkg)\n","print(f\"Decision Tree accuracy with soundex package on dev-test set: {accuracy_dt_pkg:.4f}\")"]},{"cell_type":"markdown","source":["We can see that both classifiers improved significantly from adding more features with Naive Bayes going from .628 to .856 and Decision Tree .628 to .706.\n","\n","Since our Naive Bayes outperformed our Decision Tree, we will focus on that one and use this trained classifier on our test set."],"metadata":{"id":"Wc52voN7uIYc"},"id":"Wc52voN7uIYc"},{"cell_type":"code","execution_count":44,"id":"d3f778aa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3f778aa","executionInfo":{"status":"ok","timestamp":1751873392996,"user_tz":240,"elapsed":112,"user":{"displayName":"Ariann C","userId":"03460121609660078047"}},"outputId":"05ba1213-c78f-44f2-a2ba-9d6baababc0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Final accuracy of the best classifier on the test set: 0.8380\n","Accuracy of the same classifier on the dev-test set: 0.8560\n"]}],"source":["#Final evaluation on the test set with the Naive Bayes classifier\n","final_accuracy_test_pkg = nltk.classify.accuracy(classifier_nb_pkg, test_set_pkg)\n","print(f\"\\nFinal accuracy of the best classifier on the test set: {final_accuracy_test_pkg:.4f}\")\n","print(f\"Accuracy of the same classifier on the dev-test set: {accuracy_nb_pkg:.4f}\")"]},{"cell_type":"markdown","source":["Above is the accuracy for using the Naive Bayes classifier on the test set. We can see that the accuracy actually decreased a bit from the dev-test set. However, this is kind of expected as both the dev-test and test sets only have 500 names each which is a pretty small sample. It could also reflect the effects of a wide train to test ratio gap: the dev-test and test sets combined make up just 12.5% of the data, where we typically use a train to test ratio in the range, 70:30 to 80:20. With limited data, even a few misclassifications can shift the accuracy by a couple of percentage points. The difference we saw (around 2%) is minor and not unusual in machine learning, especially with small datasets like this one. It also shows that male and female names likely donâ€™t differ that drastically in the features we used, so variation between the dev-test and test set results is minimal. I think this shows that while the model does well on a smaller validation set, real-world performance can dip slightly which is something you'd expect.\n","\n","\n"],"metadata":{"id":"UC_rNj4uuw9y"},"id":"UC_rNj4uuw9y"}],"metadata":{"kernelspec":{"display_name":"data620","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}